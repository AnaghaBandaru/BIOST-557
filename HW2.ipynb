{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdeac31",
   "metadata": {},
   "source": [
    "# <font color=black>DATA 557 Homework 2</font>\n",
    "***\n",
    "### <font color=black>Question 1\n",
    "A manufacturing process is run at a temperature of 60 deg C. The manufacturer would like to know if \n",
    "increasing the temperature would yield an increase in output. Increasing the temperature would be more \n",
    "expensive, so an increase would only be used in future if it increased output. It seems unlikely that \n",
    "increasing the temperature would decrease output and, even if it did, there would be no value in having \n",
    "that information. An experiment was performed to assess the effect of temperature on the output of a \n",
    "manufacturing process. For this experiment, temperatures of 60 or 75 degrees C were randomly assigned \n",
    "to process runs. It was desired to gather more information about output at the new temperature so \n",
    "temperatures were randomly assigned to process runs at a ratio of 2 to 1 (2 runs at temperature 75 for \n",
    "every 1 at temperature 60). The process output was recorded from each run. The variables in the data set \n",
    "are: \\\n",
    "run: Run number \\\n",
    "temp: Temperature \\\n",
    "output: Process output</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15748b92",
   "metadata": {},
   "source": [
    "__1.1. Perform the large-sample Z-test to compare mean output for the two temperatures. Give the value of \n",
    "the test statistic and the p-value for the test.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04c2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ce52c",
   "metadata": {},
   "source": [
    "Since the question specifies that there is no value in having information on decreasing output due to an increase in temperatures, I am considering a __One Tailed large-sample Z-test__.\n",
    "<br>\n",
    "We can define the null hypothesis as : <br>\n",
    "<center> H0 : μ75 - μ60 <= 0 <br>\n",
    "                           H1 : μ75 - μ60 > 0 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b13472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "\u001b[1mOne Tailed Z Test : \tTest statistic: 2.551155\n",
      "\u001b[1m\t\t\tp-value : 0.005368\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/temperature_experiment.csv\")\n",
    "temp60 = df.loc[(df[\"temp\"] == 60)]\n",
    "temp75 = df.loc[(df[\"temp\"] == 75)]\n",
    "var60 = stat.stdev(temp60['output'])**2\n",
    "var75 = stat.stdev(temp75['output'])**2\n",
    "print(len(temp60))\n",
    "test_statistic = (temp75[\"output\"].mean()-temp60[\"output\"].mean())/(((var75/20)+(var60/10))**0.5) \n",
    "p_val = stats.norm.sf(abs(test_statistic)) \n",
    "print('\\033[1m'+'One Tailed Z Test : '+'\\tTest statistic: %f' %(test_statistic))\n",
    "print('\\033[1m'+'\\t\\t\\tp-value : %f' %(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c512e9",
   "metadata": {},
   "source": [
    "__1.2. Do you reject the null hypothesis at a significance level of 0.05?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d0d5fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mZ critical : 1.644854\n",
      "\u001b[1mSignificance Level : 0.05\n",
      "\u001b[1mp-value : 0.005368\n"
     ]
    }
   ],
   "source": [
    "z_crit = stats.norm.ppf(q=0.95)\n",
    "print('\\033[1m'+\"Z critical : %f\" %(z_crit))\n",
    "print('\\033[1m'+\"Significance Level : 0.05\")\n",
    "print('\\033[1m'+'p-value : %f' %(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77fe2e",
   "metadata": {},
   "source": [
    "Since p-value is less than a 0.05 significance level, we __Reject__ the null hypothesis.\n",
    "So we can with 0.05 significance level, we can say that with an increase in temperature, there is an increase in output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f064b9",
   "metadata": {},
   "source": [
    "__1.3. State the null hypothesis for the test.__`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174901f0",
   "metadata": {},
   "source": [
    " μ75 is the mean output at 60 deg C\n",
    " μ60 is the mean output at 75 deg C<br>\n",
    "We can define the null hypothesis as : <br>\n",
    "<center> H0 : μ75 - μ60 <= 0 <br>\n",
    "                           H1 : μ75 - μ60 > 0 </center>\n",
    "This is a one tailed test, we consider on the right sided test as we only focus on whether the ouput increases with an increase in temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964e48e",
   "metadata": {},
   "source": [
    "__1.4. Perform the unequal-variance (Welch) t-test to compare mean output in the two temperature groups. \n",
    "Report the test statistic and the p-value for the test.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3cc2b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWelch df : 25.633485 \n",
      "\u001b[1mWelch t Test (One-tailed): \tTest statistic: 2.551155\n",
      "\u001b[1m\t\t\t\tp-value : 0.008531\n"
     ]
    }
   ],
   "source": [
    "welch_df= (((var75/20) + (var60/10))**2)/(((var75**2)/(400*19))+((var60**2)/(100*9)))\n",
    "p_val = stats.t.sf(abs(test_statistic), df=welch_df)\n",
    "#test statistic is the same as what we calculated above\n",
    "print('\\033[1m'+'Welch df : %f '%welch_df)\n",
    "print('\\033[1m'+'Welch t Test (One-tailed): '+'\\tTest statistic: %f' %(test_statistic))\n",
    "print('\\033[1m'+'\\t\\t\\t\\tp-value : %f' %(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cffaa",
   "metadata": {},
   "source": [
    "__1.5. Perform the equal-variance t-test to compare mean output in the two temperature groups. Report the \n",
    "test statistic and the p-value for the test.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3752de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mEqual Variance t-test:\n",
      "\tpooled variance : 597.387571 \n",
      "\ttest statistic : 2.551155 \n",
      "\tp value : 0.032238\n"
     ]
    }
   ],
   "source": [
    "pooled_var=((19*var75)+(9*var60))/28\n",
    "test_statistic_t = (temp75[\"output\"].mean()-temp60[\"output\"].mean())/(((pooled_var/20)+(pooled_var/10))**0.5) \n",
    "p_val = stats.t.sf(abs(test_statistic_t), df=28)\n",
    "print('\\033[1m'+'Equal Variance t-test:\\n\\tpooled variance : %f \\n\\ttest statistic : %f \\n\\tp value : %f'%(pooled_var,test_statistic,p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6bb7a",
   "metadata": {},
   "source": [
    "__1.6. Which of the three tests do you think is most valid for this experiment? Why?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8bce288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance temp 60 : 91.569333 \n",
      "Variance temp 75 : 836.985684\n"
     ]
    }
   ],
   "source": [
    "print(\"Variance temp 60 : %f \\nVariance temp 75 : %f\"%(var60,var75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff934231",
   "metadata": {},
   "source": [
    "Considering the large sample Z test - the sample sizes are relatively small. Hence, the sample is more likely to fit a t distribution over a nornak distribution.\n",
    "Considering the equal variance t test - we can clearly see that the variances are not equal, hence making this assumption would be wrong.\n",
    "Considering Welch t test - I believe, this is the ideal test as we are working with small samples with unequal variances.\n",
    "\n",
    "For these reasons, Welch __t-test__ is the most valid for this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8079a32",
   "metadata": {},
   "source": [
    "__1.7. Calculate a 95% confidence interval for the difference between mean output using the large-sample \n",
    "method.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72cefc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfidence Interval for large sample Z test is : (4.221947,32.218053)\n"
     ]
    }
   ],
   "source": [
    "se=(var75/20+var60/10)**0.5\n",
    "A = (temp75[\"output\"].mean()-temp60[\"output\"].mean())-1.96*se\n",
    "B = (temp75[\"output\"].mean()-temp60[\"output\"].mean())+1.96*se\n",
    "print('\\033[1m'+'Confidence Interval for large sample Z test is : (%f,%f)' %(A,B)) \n",
    "#I have reported the two tailed confidence interval in line "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512c58e",
   "metadata": {},
   "source": [
    "__1.8. Calculate a 95% confidence interval for the difference between mean output using a method that \n",
    "corresponds to the Welch test.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dcdb44aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfidence Interval is for Welch t-test is : (3.529466,32.910534)\n"
     ]
    }
   ],
   "source": [
    "t_critical=stats.t.ppf(q=1-0.05/2,df=welch_df)\n",
    "A = (temp75[\"output\"].mean()-temp60[\"output\"].mean())-(t_critical*se)\n",
    "B = (temp75[\"output\"].mean()-temp60[\"output\"].mean())+t_critical*se\n",
    "print('\\033[1m'+'Confidence Interval is for Welch t-test is : (%f,%f)' %(A,B))\n",
    "#I have reported the two tailed confidence interval in line with the announcement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826e77a",
   "metadata": {},
   "source": [
    "__1.9. Calculate a 95% confidence interval for the difference between mean output using a method that \n",
    "corresponds to the equal-variance t-test.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "807d5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfidence Interval for equal variance t-test is : (-1.170544,37.610544)\n"
     ]
    }
   ],
   "source": [
    "se=(pooled_var*((1/20)+(1/10)))**0.5\n",
    "t_critical=stats.t.ppf(q=1-0.05/2,df=28)\n",
    "A = (temp75[\"output\"].mean()-temp60[\"output\"].mean())-(t_critical*se)\n",
    "B = (temp75[\"output\"].mean()-temp60[\"output\"].mean())+t_critical*se\n",
    "print('\\033[1m'+'Confidence Interval for equal variance t-test is : (%f,%f)' %(A,B))\n",
    "#I have reported the two tailed confidence interval in line with the announcement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a77264",
   "metadata": {},
   "source": [
    "__1.10. Apart from any effect on the mean output, do the results of the experiment suggest a disadvantage of \n",
    "the higher temperature?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46f2ee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at temperature 60 deg C : \n",
      "\tMean : 1001.240000 \n",
      "\tVariance : 91.569333 \n",
      "Ouput at temperature 75 deg C : \n",
      "\tMean : 1019.460000 \n",
      "\tVariance : 836.985684\n"
     ]
    }
   ],
   "source": [
    "print(\"Output at temperature 60 deg C : \\n\\tMean : %f \\n\\tVariance : %f \\nOuput at temperature 75 deg C : \\n\\tMean : %f \\n\\tVariance : %f\"%(temp60[\"output\"].mean(),var60,temp75[\"output\"].mean(),var75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2310ef8",
   "metadata": {},
   "source": [
    "There is no significant change in the mean, but there is a considerable difference in variance when we increase temperature. It can be more likely that the output at higher temperatures in not as consistent or as stable at the lower temperature. So if the manufacturer, values consistency in their output, this could be a potential disadvantage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3e4b2",
   "metadata": {},
   "source": [
    "***\n",
    "### <font color=black>Question 2\n",
    "The data are from an experiment to compare 4 processing methods for manufacturing steel ball bearings. \n",
    "The 4 process methods were run for one day and a random sample of 1% of the ball bearings from the day \n",
    "was taken from each of the 4 methods. Because the processes produce ball bearings at different rates the \n",
    "sample sizes were not the same for the 4 methods. Each sampled ball bearing had its weight measured to \n",
    "the nearest 0.1 g and the number of surface defects was counted. The variables in the data set are: \\\n",
    "Sample: sample number \\\n",
    "Method: A, B, C, or D \\\n",
    "Defects: number of defects \\\n",
    "Weight: weight in g</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e1726",
   "metadata": {},
   "source": [
    "__2.1. The target weight for the ball bearings is 10 g. For each of the 4 methods it is desired to test the null \n",
    "hypothesis that the mean weight is equal to 10. What test should be used?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8217813",
   "metadata": {},
   "source": [
    "For this experiment, since we are only considering a 1% sample from each of the processing methods, where number of observations for each method individually are :\n",
    "A : 74\n",
    "B : 75\n",
    "C : 63\n",
    "D : 52\n",
    "I believe, the sample sizes are not large enough to conduct a z test.\n",
    "\n",
    "Since we want to test if mean weight is 10, and any values below or above this value needs to considered, for each of the 4 methods : <br> performing a __Two Tailed One Sample t Test__ is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "070b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/defects.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd39b35",
   "metadata": {},
   "source": [
    "__2.2. Give the p-values for the tests for each method. Include your R code for this question.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b68798",
   "metadata": {},
   "source": [
    "We can define the null hypothesis for each test as :\n",
    "H0 : μ = 10 <br>\n",
    "H1 : μ not equal to 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69a80b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Processing Method A :\n",
      "\tTest Statistic = 0.079652 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.936732\n",
      "For Processing Method B :\n",
      "\tTest Statistic = -0.495650 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.621610\n",
      "For Processing Method C :\n",
      "\tTest Statistic = 1.486649 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.142095\n",
      "For Processing Method D :\n",
      "\tTest Statistic = 2.068224 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.043708\n"
     ]
    }
   ],
   "source": [
    "def test_stat(df, processing_method):\n",
    "    df_pm = df.loc[(df[\"Method\"] == processing_method)]\n",
    "    test_statistic = (df_pm[\"Weight\"].mean()-10)/(stat.stdev(df_pm['Weight'])/(len(df_pm)**0.5))\n",
    "    p_val = stats.t.sf(abs(test_statistic), df=len(df_pm)-1)*2 \n",
    "    print(\"For Processing Method %s :\\n\\tTest Statistic = %f \\n\\t\\033[1mp-value\\033[0m = %f\"%(processing_method,test_statistic,p_val))\n",
    "\n",
    "processing_methods=['A','B','C','D']\n",
    "for i in processing_methods:\n",
    "    test_stat(df,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346b8df",
   "metadata": {},
   "source": [
    "__2.3. Apply a Bonferroni correction to your results from the previous question to account for inflation of \n",
    "type I error rate due to multiple testing. How does the Bonferroni correction change your conclusions? In \n",
    "particular, do you have evidence to reject the null hypothesis that the mean weight for all 4 methods is \n",
    "equal to 10, at significance level 0.05?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18b4dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mType I error rate before correction : 0.185494 \n",
      "Type I error rate after correction : 0.049070\n"
     ]
    }
   ],
   "source": [
    "error = 1 - pow(1-0.05,4)\n",
    "alpha_bonferroni = 0.05/4 #0.0125\n",
    "error_new = 1 - pow(1-alpha_bonferroni,4)\n",
    "print('\\033[1m'+\"Type I error rate before correction : %f \\nType I error rate after correction : %f\"%(error,error_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc1e71",
   "metadata": {},
   "source": [
    "In __2.2__, with a significance level of 0.05, we see that for processing methods A,B,C the p-value is greater than 0.05. But for D, the p-value(0.0437) is less than 0.05 which is why we have to __reject__ the null hypothesis that the mean for all methods is equal to 10. Also, before the correction due to multiple tests, the Type I error rate is 0.185.\n",
    "\n",
    "Now, __After Bonferroni Correction__, the new significance level is 0.0125 for each individual test, All the p-values from the processing methods (A,B,C,D) are greater than 0.0125. Therefore, with the adjusted alpha, we can conclude that at a significance level 0.05 for the experiment, we __do not have enough evidence to reject the null hypothesis__. The Type I error rate is now a more reasonable 0.049."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731693d",
   "metadata": {},
   "source": [
    "__2.4. It is is desired to compare mean weights of the 4 methods. This is to be done first by performing \n",
    "pairwise comparisons of mean weight for the different methods. What test should be used for these \n",
    "comparisons?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ac67f",
   "metadata": {},
   "source": [
    "As we discussed before, since we only have 1% of the data, our sample size is relatively small, <br>\n",
    "We can consider the samples to be independent as they were collected randomly<br>\n",
    "We are interested to know how the mean weights differ for each of these pairs, so assuming equal variance, we can use a __two sample two tailed equal variance t-test__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c284e",
   "metadata": {},
   "source": [
    "__2.5. Report the p-values from all pairwise comparisons. Include your R code for this question.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc8c0d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Pair (A,B) :\n",
      "\tTest Statistic = 0.411090 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.681606\n",
      "For Pair (A,C) :\n",
      "\tTest Statistic = -1.264579 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.208185\n",
      "For Pair (A,D) :\n",
      "\tTest Statistic = -2.086270 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.039004\n",
      "For Pair (B,C) :\n",
      "\tTest Statistic = -1.567992 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.119190\n",
      "For Pair (B,D) :\n",
      "\tTest Statistic = -2.328241 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.021506\n",
      "For Pair (C,D) :\n",
      "\tTest Statistic = -0.884224 \n",
      "\t\u001b[1mp-value\u001b[0m = 0.378437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test(df, pair):\n",
    "    df_pm1,df_pm2 = [df.loc[(df[\"Method\"] == x)] for x in pair]\n",
    "    pooled_var = (((len(df_pm1)-1)*df_pm1[\"Weight\"].var())+((len(df_pm2)-1)*df_pm2[\"Weight\"].var()))/(len(df_pm1)+len(df_pm2)-2)\n",
    "    test_statistic = (df_pm1[\"Weight\"].mean()-df_pm2[\"Weight\"].mean())/((pooled_var*((1/len(df_pm1))+(1/len(df_pm2))))**0.5)\n",
    "    p_val = stats.t.sf(abs(test_statistic), df=len(df_pm1)+len(df_pm2)-2)*2\n",
    "    print(\"For Pair (%s,%s) :\\n\\tTest Statistic = %f \\n\\t\\033[1mp-value\\033[0m = %f\"%(pair[0],pair[1],test_statistic,p_val))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(i+1,4):\n",
    "        test(df,[processing_methods[i],processing_methods[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1affe7",
   "metadata": {},
   "source": [
    "__2.6. Apply a Bonferroni correction to your results of the previous question to account for inflation of type I \n",
    "error rate due to multiple testing. What conclusion would you draw from these results? Would you reject \n",
    "the null hypothesis of no difference between any pair of means among the 4 methods, at significance level \n",
    "0.05?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0bba9e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mType I error rate before correction : 0.264908 \n",
      "Type I error rate after correction : 0.048970\n"
     ]
    }
   ],
   "source": [
    "error = 1 - pow(1-0.05,6)\n",
    "alpha_bonferroni = 0.05/6 #0.00833\n",
    "error_new = 1 - pow(1-alpha_bonferroni,6)\n",
    "print('\\033[1m'+\"Type I error rate before correction : %f \\nType I error rate after correction : %f\"%(error,error_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856bb4e9",
   "metadata": {},
   "source": [
    "In __2.5__, with a significance level of 0.05, we see that for the pairs (A,D) and (B,D) the p-value is less than 0.05, which is why we have to __reject__ the null hypothesis that the mean for all methods is equal. Also, before the correction due to multiple tests, the Type I error rate is 0.264, which is inflated because we associated an alpha of 0.05 to each indidvidual test.\n",
    "\n",
    "Now, __After Bonferroni Correction__, the new significance level is 0.0083 for each individual test, All the p-values from the possible pairs are greater than 0.0083. Therefore, with the adjusted alpha, we can conclude that at a significance level 0.05 for the experiment, we __do not have enough evidence to reject the null hypothesis__. The Type I error rate is now a more reasonable 0.048."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a92701",
   "metadata": {},
   "source": [
    "__2.7. Compare the mean weights for the 4 methods using ANOVA. State the F-statistic and the p-value for the \n",
    "F-test. Include your R code for this question.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5b4a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             df     sum_sq   mean_sq         F    PR(>F)\n",
      "Method      3.0   1.289595  0.429865  2.616943  0.051475\n",
      "Residual  261.0  42.872443  0.164262       NaN       NaN\n",
      "\u001b[1m\n",
      "\n",
      "F statistic : 2.616943 \n",
      "p value : 0.051475\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "m = ols('Weight ~ Method',data=df).fit()\n",
    "anova = sm.stats.anova_lm(m,typ=1)\n",
    "print(anova)\n",
    "print('\\033[1m'+\"\\n\\nF statistic : %f \\np value : %f\"%(anova['F'][0],anova['PR(>F)'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d41c30",
   "metadata": {},
   "source": [
    "__2.8. What do you conclude from the ANOVA?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2818e4",
   "metadata": {},
   "source": [
    "In the slides, ANOVA is defined as : \"Analysis of Variance is designed to provide a single test of a null\n",
    "hypothesis of equal group means with a desired significance level. It is a\n",
    "generalization of the equal-variance t-test to the case where the number of\n",
    "means to be compared is greater than 2\"\n",
    "\n",
    "<br>\n",
    "Here we use the F-test to determine is our group means are equal. The p-value in our experiment 0.05147 is greater than 0.05 (alpha). Therefore, our null hypothesis __cannot be rejected__ because we do not have enough evidence to prove otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0368b2",
   "metadata": {},
   "source": [
    "__2.9. How does your conclusion from ANOVA compare to the conclusion from the pairwise comparisons?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8bde4",
   "metadata": {},
   "source": [
    "For the pairwaise comparisions without the bonferroni correction, we rejected the null hypothesis but for both ANOVA and two tailed equal variance t-test we concluded that we do not have enough evidence to reject the null hypothesis. Therefore, bonferroni corrected pairwise test yields the same result as ANOVA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
